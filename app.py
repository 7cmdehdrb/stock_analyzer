from flask import Flask, render_template, request, jsonify
import pandas as pd
import yfinance as yf
import numpy as np
from datetime import datetime, timedelta
import io
import traceback
import sqlite3
import os
from flask_sqlalchemy import SQLAlchemy
from flask_admin import Admin
from flask_admin.contrib.sqla import ModelView
from dotenv import load_dotenv
import openai

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

app = Flask(__name__)
app.config["SECRET_KEY"] = "your-secret-key-here"
app.config["SQLALCHEMY_DATABASE_URI"] = (
    f"sqlite:///{os.path.join(os.path.dirname(__file__), 'stock_cache.db')}"
)
app.config["SQLALCHEMY_TRACK_MODIFICATIONS"] = False

# OpenAI API í‚¤ ì„¤ì •
openai.api_key = os.getenv("OPENAI_API_KEY")

# AI ë¶„ì„ rate limitingê³¼ ìºì‹±ì„ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
ai_analysis_cache = {}  # {ip: {"timestamp": datetime, "result": dict}}
ai_analysis_rate_limit = {}  # {ip: last_request_time}

# DB íŒŒì¼ ê²½ë¡œ
DB_PATH = os.path.join(os.path.dirname(__file__), "stock_cache.db")

# SQLAlchemy ì„¤ì •
db = SQLAlchemy(app)


# SQLAlchemy ëª¨ë¸ ì •ì˜
class StockPriceCache(db.Model):
    __tablename__ = "stock_price_cache"

    ticker = db.Column(db.String(20), primary_key=True)
    date = db.Column(db.String(10), primary_key=True)
    close_price = db.Column(db.Float, nullable=False)
    created_at = db.Column(db.DateTime, default=datetime.now)

    def __repr__(self):
        return f"<StockPrice {self.ticker} {self.date}>"


class SavedPortfolio(db.Model):
    __tablename__ = "saved_portfolios"

    id = db.Column(db.Integer, primary_key=True, autoincrement=True)
    name = db.Column(db.String(200), nullable=False)
    csv_content = db.Column(db.Text, nullable=False)
    start_date = db.Column(db.String(10))
    benchmark_ticker = db.Column(db.String(20))
    base_currency = db.Column(db.String(3))
    created_at = db.Column(db.DateTime, default=datetime.now)
    last_accessed = db.Column(db.DateTime, default=datetime.now)

    def __repr__(self):
        return f"<Portfolio {self.name}>"


# Flask-Admin ModelView ì •ì˜
class StockPriceCacheAdmin(ModelView):
    column_list = ["ticker", "date", "close_price", "created_at"]
    column_searchable_list = ["ticker"]
    column_sortable_list = ["ticker", "date", "created_at"]
    column_default_sort = [("ticker", False), ("date", True)]
    page_size = 50
    can_export = True
    export_types = ["csv", "xlsx"]


class SavedPortfolioAdmin(ModelView):
    column_list = [
        "id",
        "name",
        "start_date",
        "benchmark_ticker",
        "base_currency",
        "created_at",
        "last_accessed",
    ]
    column_searchable_list = ["name", "benchmark_ticker"]
    column_sortable_list = ["id", "name", "created_at", "last_accessed"]
    column_default_sort = [("last_accessed", True)]
    page_size = 50
    can_export = True
    export_types = ["csv", "xlsx"]
    # CSV ë‚´ìš©ì€ ë„ˆë¬´ ê¸¸ì–´ì„œ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì œì™¸
    column_exclude_list = ["csv_content"]
    # ìƒì„¸ë³´ê¸°/ìˆ˜ì •ì—ì„œëŠ” í‘œì‹œ
    form_excluded_columns = []


# Flask-Admin ì´ˆê¸°í™”
admin = Admin(app, name="Portfolio Admin", template_mode="bootstrap3")
admin.add_view(StockPriceCacheAdmin(StockPriceCache, db.session, name="Stock Prices"))
admin.add_view(SavedPortfolioAdmin(SavedPortfolio, db.session, name="Portfolios"))


def init_database():
    """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ë° í…Œì´ë¸” ìƒì„±"""
    # SQLAlchemyë¡œ í…Œì´ë¸” ìƒì„± (ì´ë¯¸ ì¡´ì¬í•˜ë©´ ë¬´ì‹œ)
    with app.app_context():
        db.create_all()


def get_cached_prices(ticker, start_date, end_date):
    """DBì—ì„œ ìºì‹œëœ ê°€ê²© ë°ì´í„° ì¡°íšŒ"""
    conn = None
    try:
        conn = sqlite3.connect(DB_PATH, timeout=30.0)
        cursor = conn.cursor()

        query = """
            SELECT date, close_price 
            FROM stock_price_cache 
            WHERE ticker = ? AND date >= ? AND date <= ?
            ORDER BY date
        """

        start_str = start_date.strftime("%Y-%m-%d")
        end_str = end_date.strftime("%Y-%m-%d")

        cursor.execute(query, (ticker, start_str, end_str))
        results = cursor.fetchall()

        if not results:
            return None

        # DataFrameìœ¼ë¡œ ë³€í™˜
        df = pd.DataFrame(results, columns=["date", "close_price"])
        df["date"] = pd.to_datetime(df["date"])
        df.set_index("date", inplace=True)

        return df["close_price"]
    except Exception as e:
        return None
    finally:
        if conn:
            conn.close()


def save_prices_to_cache(ticker, price_series):
    """ê°€ê²© ë°ì´í„°ë¥¼ DBì— ì €ì¥"""
    if price_series is None or len(price_series) == 0:
        return

    conn = None
    try:
        conn = sqlite3.connect(DB_PATH, timeout=30.0)
        cursor = conn.cursor()

        # ë°ì´í„° ì¤€ë¹„ (NaN ê°’ ì œì™¸)
        data_to_insert = []
        for date, price in price_series.items():
            # NaN ê°’ ì²´í¬
            if pd.notna(price) and not np.isnan(price):
                date_str = date.strftime("%Y-%m-%d")
                data_to_insert.append((ticker, date_str, float(price)))

        if not data_to_insert:
            return

        # INSERT OR REPLACEë¡œ ì¤‘ë³µ ë°©ì§€
        cursor.executemany(
            """
            INSERT OR REPLACE INTO stock_price_cache (ticker, date, close_price)
            VALUES (?, ?, ?)
        """,
            data_to_insert,
        )

        conn.commit()
    except Exception as e:
        if conn:
            conn.rollback()
    finally:
        if conn:
            conn.close()


def get_current_exchange_rate():
    """í˜„ì¬ USD/KRW í™˜ìœ¨ ê°€ì ¸ì˜¤ê¸°"""
    try:
        # USDKRW=X í‹°ì»¤ë¡œ í™˜ìœ¨ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        krw = yf.Ticker("USDKRW=X")
        data = krw.history(period="1d")
        if not data.empty:
            return data["Close"].iloc[-1]
        else:
            # ê¸°ë³¸ê°’ (ìµœê·¼ í‰ê·  í™˜ìœ¨)
            return 1350.0
    except Exception as e:
        return 1350.0


def fetch_stock_data(ticker, start_date, end_date):
    """Yahoo Financeì—ì„œ ì£¼ê°€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (DB ìºì‹œ í™œìš©)"""
    try:
        # 1. ë¨¼ì € DB ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ
        cached_data = get_cached_prices(ticker, start_date, end_date)

        # 2. ìºì‹œì— ëª¨ë“  ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        if cached_data is not None and len(cached_data) > 0:
            # ë‚ ì§œ ë²”ìœ„ í™•ì¸
            expected_start = pd.to_datetime(start_date)
            expected_end = pd.to_datetime(end_date)
            cached_start = cached_data.index.min()
            cached_end = cached_data.index.max()

            # ìºì‹œê°€ ìš”ì²­ ë²”ìœ„ë¥¼ ëª¨ë‘ ì»¤ë²„í•˜ëŠ”ì§€ í™•ì¸ (Â±7ì¼ í—ˆìš©)
            if cached_start <= expected_start + timedelta(
                days=7
            ) and cached_end >= expected_end - timedelta(days=7):
                return cached_data

        # 3. ìºì‹œì— ì—†ìœ¼ë©´ Yahoo Financeì—ì„œ ê°€ì ¸ì˜¤ê¸°
        stock = yf.Ticker(ticker)
        data = stock.history(start=start_date, end=end_date)

        if data.empty:
            return None

        price_data = data["Close"]

        # timezone ì œê±° (ìºì‹œëœ ë°ì´í„°ì™€ ì¼ê´€ì„± ìœ ì§€)
        if hasattr(price_data.index, 'tz') and price_data.index.tz is not None:
            price_data.index = price_data.index.tz_localize(None)

        # NaN ê°’ ì œê±°
        price_data = price_data.dropna()

        if len(price_data) == 0:
            return None

        # 4. ìƒˆë¡œ ê°€ì ¸ì˜¨ ë°ì´í„°ë¥¼ DBì— ì €ì¥
        save_prices_to_cache(ticker, price_data)

        return price_data

    except Exception as e:
        return None


def normalize_ticker(ticker, country):
    """í‹°ì»¤ ì •ê·œí™” (í•œêµ­ ì¢…ëª©ì— .KS ìë™ ì¶”ê°€)"""
    ticker = str(ticker).strip()

    # í•œêµ­ ì¢…ëª©ì¸ ê²½ìš°
    if country == "í•œêµ­":
        # ìˆ«ìë¡œë§Œ ì´ë£¨ì–´ì§„ ê²½ìš° (ì˜ˆ: 005930)
        if ticker.isdigit():
            ticker = f"{ticker}.KS"
            return ticker
        # ì´ë¯¸ .KSë‚˜ .KQê°€ ë¶™ì–´ìˆì§€ ì•Šì€ ê²½ìš°
        elif not (ticker.endswith(".KS") or ticker.endswith(".KQ")):
            ticker = f"{ticker}.KS"
            return ticker

    return ticker


def merge_duplicate_tickers(portfolio_df):
    """ë™ì¼ í‹°ì»¤ë¥¼ ê°€ì§„ ì¢…ëª©ì˜ ë³´ìœ ëŸ‰ì„ í•©ì‚°"""
    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    if "í‹°ì»¤" not in portfolio_df.columns or "ë³´ìœ ëŸ‰" not in portfolio_df.columns:
        return portfolio_df

    # í‹°ì»¤ ì •ê·œí™” (í•œêµ­ ì¢…ëª©ì— .KS ì¶”ê°€)
    if "êµ­ê°€" in portfolio_df.columns:
        portfolio_df["í‹°ì»¤"] = portfolio_df.apply(
            lambda row: normalize_ticker(row["í‹°ì»¤"], row.get("êµ­ê°€", "")), axis=1
        )

    # í‹°ì»¤ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ë³´ìœ ëŸ‰ í•©ì‚°
    # ì²« ë²ˆì§¸ í–‰ì˜ ë‹¤ë¥¸ ì •ë³´(ì¢…ëª©ëª…, êµ­ê°€, ë¶„ë¥˜ ë“±)ëŠ” ìœ ì§€
    grouped = portfolio_df.groupby("í‹°ì»¤", as_index=False).agg(
        {
            "ë³´ìœ ëŸ‰": "sum",  # ë³´ìœ ëŸ‰ì€ í•©ì‚°
            **{
                col: "first"
                for col in portfolio_df.columns
                if col not in ["í‹°ì»¤", "ë³´ìœ ëŸ‰"]
            },
        }
    )

    return grouped


def fill_missing_dates(price_series, start_date, end_date):
    """íœ´ì¥ì¼ ë° ìƒì¥ì¼ë¡œ ì¸í•œ ë¹ˆ ë°ì´í„° ì²˜ë¦¬

    Args:
        price_series: ì£¼ê°€ ì‹œê³„ì—´ ë°ì´í„°
        start_date: ë¶„ì„ ì‹œì‘ ë‚ ì§œ
        end_date: ë¶„ì„ ì¢…ë£Œ ë‚ ì§œ

    Returns:
        ë³´ê°„ëœ ì£¼ê°€ ì‹œê³„ì—´ ë°ì´í„°
    """
    if price_series is None or len(price_series) == 0:
        print("  âš  fill_missing_dates: No data provided")
        return None

    try:
        print(f"  ğŸ“… Date range: {start_date.date()} to {end_date.date()}")
        print(f"  ğŸ“Š Original data: {len(price_series)} trading days")
        print(f"  ğŸ” Index type: {type(price_series.index)}, dtype: {price_series.index.dtype}")
        
        # ì›ë³¸ ë°ì´í„°ì˜ ì¸ë±ìŠ¤ë¥¼ timezone-naiveë¡œ ë³€í™˜
        if hasattr(price_series.index, 'tz') and price_series.index.tz is not None:
            print(f"  ğŸŒ Converting from timezone: {price_series.index.tz}")
            price_series.index = price_series.index.tz_localize(None)
        
        # ì¸ë±ìŠ¤ê°€ DatetimeIndexì¸ì§€ í™•ì¸
        if not isinstance(price_series.index, pd.DatetimeIndex):
            print(f"  ğŸ”„ Converting index to DatetimeIndex")
            price_series.index = pd.to_datetime(price_series.index)
        
        # ì „ì²´ ë‚ ì§œ ë²”ìœ„ ìƒì„± (ëª¨ë“  ë‚ ì§œ í¬í•¨)
        all_dates = pd.date_range(start=start_date, end=end_date, freq="D")
        
        print(f"  ï¿½ Expanded range: {len(all_dates)} days")
        print(f"  ğŸ“Š First original date: {price_series.index[0]}, Last: {price_series.index[-1]}")

        # ê¸°ì¡´ ë°ì´í„°ë¥¼ ì „ì²´ ë‚ ì§œ ë²”ìœ„ë¡œ í™•ì¥
        price_series_filled = price_series.reindex(all_dates)
        
        # ë°ì´í„°ê°€ ìˆëŠ” ì²« ë‚ ì§œ í™•ì¸ (ìƒì¥ì¼)
        first_valid_date = price_series_filled.first_valid_index()

        if first_valid_date is None:
            print("  âŒ No valid dates found after reindex")
            print(f"  ğŸ” Checking overlap: orig min={price_series.index.min()}, max={price_series.index.max()}")
            print(f"  ğŸ” Checking overlap: new min={all_dates.min()}, max={all_dates.max()}")
            # ê·¸ëƒ¥ ì›ë³¸ ë°ì´í„° ë°˜í™˜ (ë‚ ì§œ í™•ì¥ ì—†ì´)
            return price_series

        # ìƒì¥ ì´ì „ ë°ì´í„°: ìƒì¥ í›„ ì²« ê°€ê²©ìœ¼ë¡œ ì±„ì›€
        first_price = price_series_filled[first_valid_date]
        price_series_filled.loc[:first_valid_date] = first_price

        # ìƒì¥ ì´í›„ ë¹ˆ ë°ì´í„°: ì„ í˜• ë³´ê°„
        price_series_filled = price_series_filled.interpolate(method="linear", limit_direction="forward")

        # ì•„ì§ë„ ë¹ˆ ê°’ì´ ìˆë‹¤ë©´ (ë ë¶€ë¶„) forward fill
        price_series_filled = price_series_filled.ffill()
        
        # ê·¸ë˜ë„ ë‚¨ì•„ìˆëŠ” NaNì€ backward fill
        price_series_filled = price_series_filled.bfill()

        filled_count = len(all_dates) - len(price_series)
        print(f"  âœ“ Filled {filled_count} missing dates (total: {len(price_series_filled)} days)")

        return price_series_filled
        
    except Exception as e:
        print(f"  âŒ Error in fill_missing_dates: {e}")
        import traceback
        traceback.print_exc()
        # ì˜¤ë¥˜ ì‹œ ì›ë³¸ ë°ì´í„° ë°˜í™˜
        return price_series


def calculate_portfolio_returns(portfolio_df, start_date, base_currency="USD"):
    """í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ê³„ì‚° (ê¸°ì¤€ í†µí™” ì ìš©, í˜„ê¸ˆ ì œì™¸)"""
    end_date = datetime.now()

    # í˜„ì¬ í™˜ìœ¨ ê°€ì ¸ì˜¤ê¸°
    exchange_rate = get_current_exchange_rate()
    print(f"Current USD/KRW exchange rate: {exchange_rate}")

    # ê° ì¢…ëª©ì˜ ìˆ˜ìµë¥  ë°ì´í„° ìˆ˜ì§‘
    portfolio_data = {}
    cash_holdings = {}
    failed_tickers = []  # ì‹¤íŒ¨í•œ í‹°ì»¤ ì¶”ì 
    total_initial_value = 0
    total_initial_value_with_cash = 0

    for _, row in portfolio_df.iterrows():
        ticker = row["í‹°ì»¤"]
        quantity = row["ë³´ìœ ëŸ‰"]
        country = row.get("êµ­ê°€", "ë¯¸êµ­")  # ê¸°ë³¸ê°’ì€ ë¯¸êµ­
        asset_class = row.get("ë¶„ë¥˜", "")

        # í˜„ê¸ˆì¸ ê²½ìš° ë³„ë„ ì²˜ë¦¬
        if asset_class == "í˜„ê¸ˆ":
            # í˜„ê¸ˆ ê°€ì¹˜ ê³„ì‚° (í™˜ìœ¨ ì ìš©)
            if country == "í•œêµ­" and base_currency == "USD":
                cash_value = quantity / exchange_rate
            elif country == "ë¯¸êµ­" and base_currency == "KRW":
                cash_value = quantity * exchange_rate
            else:
                cash_value = quantity

            cash_holdings[ticker] = {
                "value": cash_value,
                "country": country,
                "ticker": ticker,
            }
            total_initial_value_with_cash += cash_value
            continue

        # ì£¼ê°€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        price_data = fetch_stock_data(ticker, start_date, end_date)

        if price_data is None or len(price_data) == 0:
            print(f"âš  Skipping {ticker}: No price data available")
            failed_tickers.append(ticker)  # ì‹¤íŒ¨í•œ í‹°ì»¤ ê¸°ë¡
            continue

        # í™˜ìœ¨ ì ìš©
        # ê¸°ì¤€ í†µí™”ê°€ USDì´ê³  í•œêµ­ ì£¼ì‹ì¸ ê²½ìš° -> USDë¡œ í™˜ì‚°
        # ê¸°ì¤€ í†µí™”ê°€ KRWì´ê³  ë¯¸êµ­ ì£¼ì‹ì¸ ê²½ìš° -> KRWë¡œ í™˜ì‚°
        if base_currency == "USD" and country == "í•œêµ­":
            # í•œêµ­ ì£¼ì‹ì„ USDë¡œ í™˜ì‚° (KRW / í™˜ìœ¨)
            price_data = price_data / exchange_rate
        elif base_currency == "KRW" and country == "ë¯¸êµ­":
            # ë¯¸êµ­ ì£¼ì‹ì„ KRWë¡œ í™˜ì‚° (USD * í™˜ìœ¨)
            price_data = price_data * exchange_rate

        initial_price = price_data.iloc[0]
        initial_value = initial_price * quantity
        total_initial_value += initial_value
        total_initial_value_with_cash += initial_value

        portfolio_data[ticker] = {
            "prices": price_data,
            "quantity": quantity,
            "initial_value": initial_value,
            "country": country,
            "asset_class": asset_class,
            "name": row.get("ì¢…ëª©ëª…", ticker),
        }
        print(f"âœ“ Added {ticker} to portfolio")

    if not portfolio_data:
        print(f"âŒ No valid portfolio data found. Cash holdings: {len(cash_holdings)}")
        return None, None, None, cash_holdings, total_initial_value_with_cash, failed_tickers

    # ëª¨ë“  ë‚ ì§œì˜ í•©ì§‘í•© êµ¬í•˜ê¸° (start_date ì´í›„ë§Œ)
    all_dates = pd.DatetimeIndex([])
    
    # start_dateë¥¼ timezone-naiveë¡œ ë³€í™˜ (fetch_stock_dataê°€ timezone ì—†ëŠ” ë°ì´í„° ë°˜í™˜)
    start_date_tz = pd.to_datetime(start_date)
    
    for data in portfolio_data.values():
        prices_index = data["prices"].index
        
        # start_date ì´í›„ ë°ì´í„°ë§Œ ì‚¬ìš©
        ticker_dates = prices_index[prices_index >= start_date_tz]
        all_dates = all_dates.union(ticker_dates)

    all_dates = sorted(all_dates)
    
    print(f"\nğŸ“… Portfolio date range:")
    print(f"  Start date requested: {start_date.date()}")
    print(f"  Actual start date: {all_dates[0].date() if len(all_dates) > 0 else 'N/A'}")
    print(f"  End date: {all_dates[-1].date() if len(all_dates) > 0 else 'N/A'}")
    print(f"  Total trading days: {len(all_dates)}")

    # í¬íŠ¸í´ë¦¬ì˜¤ ì „ì²´ ê°€ì¹˜ ê³„ì‚°
    portfolio_values = []

    for date in all_dates:
        daily_value = 0
        for ticker, data in portfolio_data.items():
            # í•´ë‹¹ ë‚ ì§œì˜ ê°€ê²© (ì—†ìœ¼ë©´ forward fill)
            if date in data["prices"].index:
                price = data["prices"][date]
            else:
                # ê°€ì¥ ìµœê·¼ ê°€ê²© ì‚¬ìš©
                available_prices = data["prices"][data["prices"].index <= date]
                if len(available_prices) > 0:
                    price = available_prices.iloc[-1]
                else:
                    price = data["prices"].iloc[0]

            daily_value += price * data["quantity"]

        portfolio_values.append(daily_value)

    portfolio_series = pd.Series(portfolio_values, index=all_dates)
    
    print(f"\nğŸ’° Portfolio values:")
    print(f"  Initial value: ${portfolio_series.iloc[0]:,.2f}")
    print(f"  Final value: ${portfolio_series.iloc[-1]:,.2f}")
    print(f"  Total return: {(portfolio_series.iloc[-1] / portfolio_series.iloc[0] - 1) * 100:.2f}%")

    # ì¼ì¼ ìˆ˜ìµë¥  ê³„ì‚°
    returns = portfolio_series.pct_change().dropna()
    
    print(f"\nğŸ“Š Returns statistics:")
    print(f"  Number of returns: {len(returns)}")
    print(f"  Mean daily return: {returns.mean():.6f} ({returns.mean() * 252 * 100:.2f}% annualized)")
    print(f"  Std daily return: {returns.std():.6f}")
    print(f"  Annualized volatility (âˆš252): {returns.std() * np.sqrt(252) * 100:.2f}%")
    print(f"  Annualized volatility (âˆštrading days): {returns.std() * np.sqrt(len(returns)) * 100:.2f}%")
    print(f"  Min daily return: {returns.min():.4f}")
    print(f"  Max daily return: {returns.max():.4f}")

    # í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°ì™€ í˜„ê¸ˆ ë³´ìœ  ì •ë³´ ë°˜í™˜
    return (
        returns,
        portfolio_series,
        portfolio_data,
        cash_holdings,
        total_initial_value_with_cash,
        failed_tickers,  # ì‹¤íŒ¨í•œ í‹°ì»¤ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    )


def calculate_weighted_annual_return(portfolio_returns):
    """ì—° í‰ê·  ìˆ˜ìµë¥  ê³„ì‚° (ì˜ì—…ì¼ ê°€ì¤‘í‰ê· )"""
    if len(portfolio_returns) == 0:
        return 0
    
    # ë‚ ì§œë¥¼ ì—°ë„ë³„ë¡œ ê·¸ë£¹í™”
    returns_by_year = {}
    
    for date, ret in portfolio_returns.items():
        year = date.year
        if year not in returns_by_year:
            returns_by_year[year] = []
        returns_by_year[year].append(ret)
    
    # ê° ì—°ë„ì˜ ìˆ˜ìµë¥ ê³¼ ì˜ì—…ì¼ ìˆ˜ ê³„ì‚°
    yearly_data = []
    for year, returns_list in returns_by_year.items():
        trading_days = len(returns_list)
        # í•´ë‹¹ ì—°ë„ì˜ ëˆ„ì  ìˆ˜ìµë¥ 
        year_cumulative = (1 + pd.Series(returns_list)).prod() - 1
        # ì—°ìœ¨í™” (í•´ë‹¹ ì—°ë„ì˜ ì¼ë¶€ë§Œ ìˆëŠ” ê²½ìš° ë³´ì •)
        year_return = ((1 + year_cumulative) ** (252 / trading_days) - 1) if trading_days > 0 else 0
        yearly_data.append({
            'year': year,
            'return': year_return,
            'trading_days': trading_days
        })
    
    # ì˜ì—…ì¼ ê°€ì¤‘ í‰ê· 
    total_trading_days = sum(d['trading_days'] for d in yearly_data)
    if total_trading_days == 0:
        return 0
    
    weighted_return = sum(d['return'] * d['trading_days'] for d in yearly_data) / total_trading_days
    
    print(f"\n  ğŸ“… Yearly returns (weighted by trading days):")
    for d in yearly_data:
        weight = d['trading_days'] / total_trading_days * 100
        print(f"    {d['year']}: {d['return']*100:.2f}% (weight: {weight:.1f}%, {d['trading_days']} days)")
    print(f"  Weighted average: {weighted_return*100:.2f}%")
    
    return weighted_return


def calculate_metrics(portfolio_returns, benchmark_returns):
    """ìƒ¤í”„ë¹„, ì†Œí‹°ë…¸ë¹„, ì•ŒíŒŒ, ë² íƒ€, í‰ê·  ì—° ìˆ˜ìµë¥  ê³„ì‚°"""

    # ì¸ë±ìŠ¤ ì •ë³´ ì¶œë ¥
    print(f"\nğŸ” Index comparison:")
    print(f"  Portfolio index type: {type(portfolio_returns.index)}")
    print(f"  Portfolio index tz: {getattr(portfolio_returns.index, 'tz', 'N/A')}")
    print(f"  Portfolio first date: {portfolio_returns.index[0]}")
    print(f"  Benchmark index type: {type(benchmark_returns.index)}")
    print(f"  Benchmark index tz: {getattr(benchmark_returns.index, 'tz', 'N/A')}")
    print(f"  Benchmark first date: {benchmark_returns.index[0]}")

    # timezone í†µì¼
    if hasattr(portfolio_returns.index, 'tz') and portfolio_returns.index.tz is not None:
        portfolio_returns.index = portfolio_returns.index.tz_localize(None)
        print(f"  âœ“ Removed timezone from portfolio index")
    
    if hasattr(benchmark_returns.index, 'tz') and benchmark_returns.index.tz is not None:
        benchmark_returns.index = benchmark_returns.index.tz_localize(None)
        print(f"  âœ“ Removed timezone from benchmark index")

    # ê³µí†µ ë‚ ì§œë§Œ ì‚¬ìš©
    common_dates = portfolio_returns.index.intersection(benchmark_returns.index)
    print(f"  Common dates found: {len(common_dates)}")
    
    portfolio_returns = portfolio_returns[common_dates]
    benchmark_returns = benchmark_returns[common_dates]

    if len(portfolio_returns) == 0:
        print(f"  âŒ No common dates found!")
        return None

    print(f"\nğŸ“Š Calculating metrics:")
    print(f"  Common dates: {len(common_dates)}")
    print(f"  First common date: {common_dates[0].date()}")
    print(f"  Last common date: {common_dates[-1].date()}")
    print(f"  Days in period: {(common_dates[-1] - common_dates[0]).days} calendar days")
    print(f"  Trading days: {len(common_dates)}")
    print(f"  Years: {len(common_dates) / 252:.2f}")
    print(f"\n  Portfolio returns mean: {portfolio_returns.mean():.8f}")
    print(f"  Benchmark returns mean: {benchmark_returns.mean():.8f}")
    print(f"  Portfolio returns std: {portfolio_returns.std():.8f}")
    print(f"  Benchmark returns std: {benchmark_returns.std():.8f}")
    
    # ìˆ˜ìµë¥  ì°¨ì´ í™•ì¸
    returns_diff = (portfolio_returns - benchmark_returns).abs().mean()
    print(f"  Average absolute difference: {returns_diff:.10f}")
    
    # ìƒ˜í”Œ ë¹„êµ
    print(f"\n  ğŸ“‹ Sample comparison (first 5 days):")
    for i in range(min(5, len(common_dates))):
        date = common_dates[i]
        print(f"    {date.date()}: Portfolio={portfolio_returns[date]:.6f}, Benchmark={benchmark_returns[date]:.6f}")

    # ì—°ê°„í™” ê³„ì‚°ì„ ìœ„í•œ ê±°ë˜ì¼ ìˆ˜
    trading_days = 252

    # í‰ê·  ì—° ìˆ˜ìµë¥ 
    avg_return = portfolio_returns.mean() * trading_days

    # í‘œì¤€í¸ì°¨ (ì—°ê°„í™”)
    std_dev = portfolio_returns.std() * np.sqrt(trading_days)

    # ìƒ¤í”„ ë¹„ìœ¨ (ë¬´ìœ„í—˜ ìˆ˜ìµë¥  0ìœ¼ë¡œ ê°€ì •)
    sharpe_ratio = avg_return / std_dev if std_dev != 0 else 0
    
    print(f"\n  ğŸ“ˆ Sharpe Calculation:")
    print(f"    Annualized return: {avg_return * 100:.2f}%")
    print(f"    Annualized volatility: {std_dev * 100:.2f}%")
    print(f"    Sharpe ratio: {sharpe_ratio:.4f}")

    # ì†Œí‹°ë…¸ ë¹„ìœ¨ (í•˜ë°© í‘œì¤€í¸ì°¨)
    downside_returns = portfolio_returns[portfolio_returns < 0]
    downside_std = downside_returns.std() * np.sqrt(trading_days)
    sortino_ratio = avg_return / downside_std if downside_std != 0 else 0
    
    print(f"\n  ğŸ“‰ Sortino Calculation:")
    print(f"    Downside returns count: {len(downside_returns)}/{len(portfolio_returns)}")
    print(f"    Downside volatility: {downside_std * 100:.2f}%")
    print(f"    Sortino ratio: {sortino_ratio:.4f}")

    # ë² íƒ€ ê³„ì‚° ìˆ˜ì • - ê³µë¶„ì‚°ê³¼ ë¶„ì‚° ëª¨ë‘ ì¼ì¼ ìˆ˜ìµë¥  ê¸°ì¤€
    covariance = portfolio_returns.cov(benchmark_returns)
    benchmark_variance = benchmark_returns.var()
    beta = covariance / benchmark_variance if benchmark_variance != 0 else 0

    print(f"  Covariance: {covariance:.6f}")
    print(f"  Benchmark variance: {benchmark_variance:.6f}")
    print(f"  Beta: {beta:.4f}")

    # ì•ŒíŒŒ (ì—°ê°„í™”)
    benchmark_avg_return = benchmark_returns.mean() * trading_days
    alpha = avg_return - (beta * benchmark_avg_return)
    
    print(f"  Portfolio annual return: {avg_return * 100:.2f}%")
    print(f"  Benchmark annual return: {benchmark_avg_return * 100:.2f}%")
    print(f"  Alpha: {alpha * 100:.2f}%")

    # ëˆ„ì  ìˆ˜ìµë¥ 
    cumulative_return = (1 + portfolio_returns).prod() - 1

    # ì—°ìˆ˜ ê³„ì‚°
    years = len(portfolio_returns) / trading_days

    # ì—°í‰ê·  ìˆ˜ìµë¥  (CAGR)
    if years > 0:
        cagr = (1 + cumulative_return) ** (1 / years) - 1
    else:
        cagr = 0

    # ë²¤ì¹˜ë§ˆí¬ CAGR ê³„ì‚°
    benchmark_cumulative_return = (1 + benchmark_returns).prod() - 1
    if years > 0:
        benchmark_cagr = (1 + benchmark_cumulative_return) ** (1 / years) - 1
    else:
        benchmark_cagr = 0

    # ë²¤ì¹˜ë§ˆí¬ ìƒ¤í”„/ì†Œí‹°ë…¸ ê³„ì‚°
    benchmark_std = benchmark_returns.std() * np.sqrt(trading_days)
    benchmark_sharpe = benchmark_avg_return / benchmark_std if benchmark_std != 0 else 0
    
    benchmark_downside_returns = benchmark_returns[benchmark_returns < 0]
    benchmark_downside_std = benchmark_downside_returns.std() * np.sqrt(trading_days)
    benchmark_sortino = benchmark_avg_return / benchmark_downside_std if benchmark_downside_std != 0 else 0

    print(f"\n  ğŸ“Š Benchmark metrics:")
    print(f"    Sharpe: {benchmark_sharpe:.4f}")
    print(f"    Sortino: {benchmark_sortino:.4f}")
    print(f"    CAGR: {benchmark_cagr * 100:.2f}%")

    # ì—° í‰ê·  ìˆ˜ìµë¥  (ì˜ì—…ì¼ ê°€ì¤‘í‰ê· ) ê³„ì‚°
    weighted_annual_return = calculate_weighted_annual_return(portfolio_returns)

    metrics = {
        "sharpe_ratio": round(sharpe_ratio, 4),
        "sortino_ratio": round(sortino_ratio, 4),
        "benchmark_sharpe_ratio": round(benchmark_sharpe, 4),
        "benchmark_sortino_ratio": round(benchmark_sortino, 4),
        "alpha": round(alpha * 100, 2),  # í¼ì„¼íŠ¸ë¡œ ë³€í™˜
        "beta": round(beta, 4),
        "annual_return": round(avg_return * 100, 2),  # í¼ì„¼íŠ¸ë¡œ ë³€í™˜
        "weighted_annual_return": round(weighted_annual_return * 100, 2),  # ì—° í‰ê·  ìˆ˜ìµë¥ 
        "benchmark_annual_return": round(benchmark_cagr * 100, 2),  # ë²¤ì¹˜ë§ˆí¬ CAGR
        "cagr": round(cagr * 100, 2),  # í¼ì„¼íŠ¸ë¡œ ë³€í™˜
        "cumulative_return": round(cumulative_return * 100, 2),
        "volatility": round(std_dev * 100, 2),
        "benchmark_volatility": round(benchmark_std * 100, 2),
    }

    return metrics


def prepare_chart_data(portfolio_returns, benchmark_returns, portfolio_series):
    """ì°¨íŠ¸ ë°ì´í„° ì¤€ë¹„"""
    # timezone í†µì¼ (calculate_metricsì™€ ë™ì¼)
    if hasattr(portfolio_returns.index, 'tz') and portfolio_returns.index.tz is not None:
        portfolio_returns.index = portfolio_returns.index.tz_localize(None)
    
    if hasattr(benchmark_returns.index, 'tz') and benchmark_returns.index.tz is not None:
        benchmark_returns.index = benchmark_returns.index.tz_localize(None)
    
    if hasattr(portfolio_series.index, 'tz') and portfolio_series.index.tz is not None:
        portfolio_series.index = portfolio_series.index.tz_localize(None)
    
    common_dates = portfolio_returns.index.intersection(benchmark_returns.index)

    # ëˆ„ì  ìˆ˜ìµë¥  ê³„ì‚°
    portfolio_cumulative = (1 + portfolio_returns[common_dates]).cumprod()
    benchmark_cumulative = (1 + benchmark_returns[common_dates]).cumprod()

    # ë‚ ì§œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
    dates = [date.strftime("%Y-%m-%d") for date in common_dates]

    chart_data = {
        "dates": dates,
        "portfolio_cumulative": [
            round(val, 4) for val in portfolio_cumulative.tolist()
        ],
        "benchmark_cumulative": [
            round(val, 4) for val in benchmark_cumulative.tolist()
        ],
        "portfolio_values": [
            round(val, 2) for val in portfolio_series[common_dates].tolist()
        ],
    }

    return chart_data


def prepare_allocation_data(
    portfolio_data, cash_holdings, total_initial_value_with_cash
):
    """ë„ë„› ì°¨íŠ¸ìš© ìì‚° ë°°ë¶„ ë°ì´í„° ì¤€ë¹„"""

    # ì‹œì‘ ì‹œì  ë°°ë¶„
    initial_allocation = {}
    for ticker, data in portfolio_data.items():
        name = data.get("name", ticker)
        initial_allocation[name] = data["initial_value"]

    # í˜„ê¸ˆ ì¶”ê°€
    for ticker, cash_data in cash_holdings.items():
        name = f"í˜„ê¸ˆ ({cash_data['country']})"
        if name in initial_allocation:
            initial_allocation[name] += cash_data["value"]
        else:
            initial_allocation[name] = cash_data["value"]

    # í˜„ì¬ ì‹œì  ë°°ë¶„
    current_allocation = {}
    for ticker, data in portfolio_data.items():
        name = data.get("name", ticker)
        current_price = data["prices"].iloc[-1]
        current_value = current_price * data["quantity"]
        current_allocation[name] = current_value

    # í˜„ê¸ˆ ì¶”ê°€ (í˜„ê¸ˆì€ ê°€ì¹˜ ë³€ë™ ì—†ìŒ)
    for ticker, cash_data in cash_holdings.items():
        name = f"í˜„ê¸ˆ ({cash_data['country']})"
        if name in current_allocation:
            current_allocation[name] += cash_data["value"]
        else:
            current_allocation[name] = cash_data["value"]

    # ìƒìœ„ 10ê°œ ì¢…ëª©ë§Œ í‘œì‹œ, ë‚˜ë¨¸ì§€ëŠ” "ê¸°íƒ€"ë¡œ ë¬¶ê¸°
    def get_top_allocations(allocation_dict, top_n=10):
        sorted_items = sorted(allocation_dict.items(), key=lambda x: x[1], reverse=True)

        if len(sorted_items) <= top_n:
            return dict(sorted_items)

        top_items = dict(sorted_items[:top_n])
        others_sum = sum(value for _, value in sorted_items[top_n:])
        if others_sum > 0:
            top_items["ê¸°íƒ€"] = others_sum

        return top_items

    initial_top = get_top_allocations(initial_allocation)
    current_top = get_top_allocations(current_allocation)

    return {
        "initial": {
            "labels": list(initial_top.keys()),
            "values": [round(v, 2) for v in initial_top.values()],
        },
        "current": {
            "labels": list(current_top.keys()),
            "values": [round(v, 2) for v in current_top.values()],
        },
    }


def prepare_holdings_table(portfolio_data, cash_holdings, base_currency, exchange_rate):
    """ë³´ìœ  ì¢…ëª© í…Œì´ë¸” ë°ì´í„° ì¤€ë¹„ (í˜„ì¬ ì‹œì  ê¸°ì¤€)"""
    holdings = []

    # íˆ¬ì ìì‚°
    for ticker, data in portfolio_data.items():
        current_price = data["prices"].iloc[-1]
        quantity = data["quantity"]
        current_value = current_price * quantity
        name = data.get("name", ticker)

        holdings.append(
            {
                "ticker": ticker,
                "name": name,
                "quantity": quantity,
                "current_value": round(current_value, 2),
                "asset_class": data.get("asset_class", ""),
            }
        )

    # í˜„ê¸ˆ
    for ticker, cash_data in cash_holdings.items():
        holdings.append(
            {
                "ticker": ticker,
                "name": f"í˜„ê¸ˆ ({cash_data['country']})",
                "quantity": cash_data["value"],
                "current_value": round(cash_data["value"], 2),
                "asset_class": "í˜„ê¸ˆ",
            }
        )

    # ì´ ê°€ì¹˜ ê³„ì‚°
    total_value = sum(h["current_value"] for h in holdings)

    # ë¹„ì¤‘ ê³„ì‚°
    for holding in holdings:
        holding["weight"] = (
            round((holding["current_value"] / total_value * 100), 2)
            if total_value > 0
            else 0
        )

    # í˜„ì¬ ê°€ì¹˜ ê¸°ì¤€ ì •ë ¬
    holdings.sort(key=lambda x: x["current_value"], reverse=True)

    return holdings


@app.route("/")
def index():
    """ë©”ì¸ í˜ì´ì§€"""
    return render_template("index.html")


@app.route("/api/cache-stats", methods=["GET"])
def get_cache_stats():
    """ìºì‹œ í†µê³„ ì¡°íšŒ"""
    conn = None
    try:
        conn = sqlite3.connect(DB_PATH, timeout=30.0)
        cursor = conn.cursor()
        
        # ìºì‹œëœ í‹°ì»¤ ìˆ˜ì™€ ë ˆì½”ë“œ ìˆ˜ ì¡°íšŒ
        cursor.execute("""
            SELECT COUNT(DISTINCT ticker) as ticker_count,
                   COUNT(*) as record_count
            FROM stock_price_cache
        """)
        
        result = cursor.fetchone()
        ticker_count = result[0] if result else 0
        record_count = result[1] if result else 0
        
        return jsonify({
            "ticker_count": ticker_count,
            "record_count": record_count
        })
    except Exception as e:
        print(f"Error getting cache stats: {e}")
        return jsonify({"error": str(e)}), 500
    finally:
        if conn:
            conn.close()


@app.route("/api/save-portfolio", methods=["POST"])
def save_portfolio():
    """í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ ê²°ê³¼ ì €ì¥"""
    try:
        data = request.json
        
        # í•„ìˆ˜ ë°ì´í„° í™•ì¸
        required_fields = ["name", "csv_content", "start_date", "benchmark_ticker", "base_currency", 
                          "metrics", "summary", "holdings_table", "allocation_data", "chart_data"]
        
        missing_fields = [field for field in required_fields if field not in data]
        if missing_fields:
            return jsonify({"error": f"í•„ìˆ˜ ë°ì´í„° ëˆ„ë½: {', '.join(missing_fields)}"}), 400
        
        # JSONìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
        import json
        
        portfolio = SavedPortfolio(
            name=data["name"],
            csv_content=data["csv_content"],
            start_date=data["start_date"],
            benchmark_ticker=data["benchmark_ticker"],
            base_currency=data["base_currency"],
            created_at=datetime.now(),
            last_accessed=datetime.now()
        )
        
        # ë¶„ì„ ê²°ê³¼ë¥¼ csv_contentì— JSONìœ¼ë¡œ ì¶”ê°€ ì €ì¥
        full_data = {
            "csv_content": data["csv_content"],
            "metrics": data["metrics"],
            "summary": data["summary"],
            "holdings_table": data["holdings_table"],
            "allocation_data": data["allocation_data"],
            "chart_data": data["chart_data"]
        }
        portfolio.csv_content = json.dumps(full_data, ensure_ascii=False)
        
        db.session.add(portfolio)
        db.session.commit()
        
        return jsonify({
            "success": True,
            "portfolio_id": portfolio.id,
            "message": f"í¬íŠ¸í´ë¦¬ì˜¤ '{data['name']}'ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
        })
        
    except Exception as e:
        db.session.rollback()
        error_trace = traceback.format_exc()
        print("=" * 80)
        print("âŒ ERROR in /api/save-portfolio endpoint:")
        print(error_trace)
        print("=" * 80)
        return jsonify({"error": f"ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}), 500


@app.route("/ranking")
def ranking():
    """ë­í‚¹ í˜ì´ì§€"""
    return render_template("ranking.html")


@app.route("/api/rankings", methods=["GET"])
def get_rankings():
    """í¬íŠ¸í´ë¦¬ì˜¤ ë­í‚¹ ë°ì´í„° ì¡°íšŒ"""
    try:
        import json
        
        # ë²¤ì¹˜ë§ˆí¬ í•„í„° íŒŒë¼ë¯¸í„° ë°›ê¸°
        benchmark_filter = request.args.get('benchmark', None)
        
        # ë²¤ì¹˜ë§ˆí¬ ë§¤í•‘ (í”„ë¡ íŠ¸ì—”ë“œ í‘œì‹œëª… -> ì‹¤ì œ í‹°ì»¤ë“¤)
        # ì—¬ëŸ¬ ê°€ëŠ¥í•œ í‹°ì»¤ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ê´€ë¦¬
        benchmark_mapping = {
            'S&P500': ['SPY', '^GSPC'],
            'NASDAQ100': ['QQQ', '^NDX'],
            'KODEX200': ['069500.KS']
        }
        
        portfolios = SavedPortfolio.query.all()
        
        if not portfolios:
            return jsonify({
                "cagr": [],
                "sortino": [],
                "sharpe": [],
                "alpha": [],
                "beta": []
            })
        
        # í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„° íŒŒì‹±
        portfolio_list = []
        for p in portfolios:
            try:
                data = json.loads(p.csv_content)
                
                # ë²¤ì¹˜ë§ˆí¬ í•„í„°ë§
                if benchmark_filter and benchmark_filter != 'ì „ì²´':
                    expected_tickers = benchmark_mapping.get(benchmark_filter, [])
                    # benchmark_tickerê°€ ì—†ê±°ë‚˜ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ ìŠ¤í‚µ
                    if not p.benchmark_ticker or p.benchmark_ticker not in expected_tickers:
                        continue
                
                portfolio_list.append({
                    "id": p.id,
                    "name": p.name,
                    "created_at": p.created_at.isoformat(),
                    "benchmark": p.benchmark_ticker,
                    "metrics": data.get("metrics", {})
                })
            except Exception as e:
                print(f"Error parsing portfolio {p.id}: {e}")
                continue
        
        # ê° ì§€í‘œë³„ Top 5
        cagr_top = sorted(portfolio_list, key=lambda x: x["metrics"].get("cagr", -999999), reverse=True)[:5]
        sortino_top = sorted(portfolio_list, key=lambda x: x["metrics"].get("sortino_ratio", -999999), reverse=True)[:5]
        sharpe_top = sorted(portfolio_list, key=lambda x: x["metrics"].get("sharpe_ratio", -999999), reverse=True)[:5]
        alpha_top = sorted(portfolio_list, key=lambda x: x["metrics"].get("alpha", -999999), reverse=True)[:5]
        
        # ë² íƒ€ëŠ” 1.0ì— ê°€ê¹Œìš´ ìˆœ
        beta_top = sorted(portfolio_list, key=lambda x: abs(x["metrics"].get("beta", 999999) - 1.0))[:5]
        
        return jsonify({
            "cagr": cagr_top,
            "sortino": sortino_top,
            "sharpe": sharpe_top,
            "alpha": alpha_top,
            "beta": beta_top
        })
        
    except Exception as e:
        error_trace = traceback.format_exc()
        print("=" * 80)
        print("âŒ ERROR in /api/rankings endpoint:")
        print(error_trace)
        print("=" * 80)
        return jsonify({"error": str(e)}), 500


@app.route("/portfolio/<int:portfolio_id>")
def view_portfolio(portfolio_id):
    """ì €ì¥ëœ í¬íŠ¸í´ë¦¬ì˜¤ ìƒì„¸ë³´ê¸°"""
    try:
        import json
        
        portfolio = SavedPortfolio.query.get_or_404(portfolio_id)
        
        # ë§ˆì§€ë§‰ ì ‘ê·¼ ì‹œê°„ ì—…ë°ì´íŠ¸
        portfolio.last_accessed = datetime.now()
        db.session.commit()
        
        # ë°ì´í„° íŒŒì‹±
        data = json.loads(portfolio.csv_content)
        
        # ë¶„ì„ ê²°ê³¼ í˜ì´ì§€ì— ì „ë‹¬
        return render_template("portfolio_view.html", 
                             portfolio=portfolio,
                             data=data)
        
    except Exception as e:
        error_trace = traceback.format_exc()
        print("=" * 80)
        print("âŒ ERROR in /portfolio/<id> endpoint:")
        print(error_trace)
        print("=" * 80)
        return f"í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}", 500


@app.route("/analyze", methods=["POST"])
def analyze():
    """í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„"""
    try:
        # CSV íŒŒì¼ ì½ê¸°
        if "csv_file" not in request.files:
            return jsonify({"error": "CSV íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400

        file = request.files["csv_file"]

        if file.filename == "":
            return jsonify({"error": "íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400

        print(f"ğŸ“ Received file: {file.filename}")

        start_date = request.form.get("start_date")
        benchmark_ticker = request.form.get("benchmark_ticker")
        base_currency = request.form.get("base_currency", "USD")

        if not start_date or not benchmark_ticker:
            return jsonify({"error": "ì‹œì‘ ì¼ìì™€ ë²¤ì¹˜ë§ˆí¬ í‹°ì»¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."}), 400

        # CSV íŒŒì¼ íŒŒì‹±
        csv_content = file.read().decode("utf-8")
        print(f"ğŸ“„ CSV content length: {len(csv_content)} bytes")

        portfolio_df = pd.read_csv(io.StringIO(csv_content))

        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_columns = ["í‹°ì»¤", "ë³´ìœ ëŸ‰", "êµ­ê°€", "ë¶„ë¥˜"]
        missing_columns = [
            col for col in required_columns if col not in portfolio_df.columns
        ]

        if missing_columns:
            return (
                jsonify(
                    {
                        "error": f'CSV íŒŒì¼ì— ë‹¤ìŒ ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤: {", ".join(missing_columns)}'
                    }
                ),
                400,
            )

        # ë™ì¼ í‹°ì»¤ ë³‘í•©
        portfolio_df = merge_duplicate_tickers(portfolio_df)

        # ë‚ ì§œ ë³€í™˜
        start_date_obj = datetime.strptime(start_date, "%Y-%m-%d")

        # í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ê³„ì‚° (ê¸°ì¤€ í†µí™” ì „ë‹¬)
        print(f"ğŸ“Š Starting portfolio calculation with {len(portfolio_df)} items...")
        result = calculate_portfolio_returns(
            portfolio_df, start_date_obj, base_currency
        )

        if result is None or result[0] is None:
            print("âŒ Portfolio calculation failed - no valid data")
            
            # ì‹¤íŒ¨í•œ í‹°ì»¤ ì •ë³´ ì¶”ì¶œ
            failed_tickers = result[5] if result and len(result) > 5 else []
            
            error_msg = "í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            if failed_tickers:
                error_msg += f" ë‹¤ìŒ í‹°ì»¤ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤: {', '.join(failed_tickers)}"
            else:
                error_msg += " ê°€ëŠ¥í•œ ì›ì¸: 1) ëª¨ë“  í‹°ì»¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŒ, 2) ì‹œì‘ ë‚ ì§œê°€ ë„ˆë¬´ ìµœê·¼, 3) ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜"
            
            return jsonify({"error": error_msg}), 400

        (
            portfolio_returns,
            portfolio_series,
            portfolio_data,
            cash_holdings,
            total_initial_value_with_cash,
            failed_tickers,  # ì‹¤íŒ¨í•œ í‹°ì»¤ ë¦¬ìŠ¤íŠ¸ ë°›ê¸°
        ) = result

        print(
            f"âœ“ Portfolio calculation successful: {len(portfolio_data)} stocks, {len(cash_holdings)} cash items"
        )
        
        # ì¼ë¶€ í‹°ì»¤ê°€ ì‹¤íŒ¨í•œ ê²½ìš° ê²½ê³  ë©”ì‹œì§€ ì¶”ê°€
        warning_msg = None
        if failed_tickers:
            warning_msg = f"âš ï¸ ë‹¤ìŒ í‹°ì»¤ì˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì–´ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(failed_tickers)}"
            print(f"âš ï¸ Warning: Some tickers failed: {failed_tickers}")

        # ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        print(f"ğŸ“Š Fetching benchmark data: {benchmark_ticker}")
        benchmark_data = fetch_stock_data(
            benchmark_ticker, start_date_obj, datetime.now()
        )

        if benchmark_data is None:
            print(f"âŒ Failed to fetch benchmark data for {benchmark_ticker}")
            return (
                jsonify(
                    {
                        "error": f'ë²¤ì¹˜ë§ˆí¬ í‹°ì»¤ "{benchmark_ticker}"ì˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í‹°ì»¤ ì´ë¦„ì„ í™•ì¸í•˜ì„¸ìš”.'
                    }
                ),
                400,
            )

        # ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ë„ start_date ì´í›„ë§Œ ì‚¬ìš©
        print(f"ğŸ“Š Benchmark data before filter: {len(benchmark_data)} days")
        
        # fetch_stock_dataê°€ timezone ì—†ëŠ” ë°ì´í„° ë°˜í™˜í•˜ë¯€ë¡œ ë‹¨ìˆœ ë¹„êµ
        start_date_for_filter = pd.to_datetime(start_date_obj)
        
        benchmark_data = benchmark_data[benchmark_data.index >= start_date_for_filter]
        print(f"ğŸ“Š Benchmark data after filter: {len(benchmark_data)} days")
        if len(benchmark_data) > 0:
            print(f"    Date range: {benchmark_data.index[0].date()} to {benchmark_data.index[-1].date()}")
        else:
            print(f"    âŒ No benchmark data after filtering!")
            return (
                jsonify(
                    {"error": f"ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ê°€ ì‹œì‘ ë‚ ì§œ({start_date}) ì´í›„ì— ì—†ìŠµë‹ˆë‹¤. ë‚ ì§œë¥¼ í™•ì¸í•˜ì„¸ìš”."}
                ),
                400,
            )

        benchmark_returns = benchmark_data.pct_change().dropna()
        
        print(f"ğŸ“Š Returns comparison:")
        print(f"  Portfolio returns: {len(portfolio_returns)} days")
        print(f"  Benchmark returns: {len(benchmark_returns)} days")
        
        if len(benchmark_returns) == 0:
            print(f"    âŒ No benchmark returns after pct_change!")
            return (
                jsonify(
                    {"error": "ë²¤ì¹˜ë§ˆí¬ ìˆ˜ìµë¥ ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."}
                ),
                400,
            )

        # ì§€í‘œ ê³„ì‚°
        metrics = calculate_metrics(portfolio_returns, benchmark_returns)

        if metrics is None:
            print(f"    âŒ calculate_metrics returned None")
            return (
                jsonify(
                    {"error": "ì§€í‘œë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í¬íŠ¸í´ë¦¬ì˜¤ì™€ ë²¤ì¹˜ë§ˆí¬ì˜ ë‚ ì§œ ë²”ìœ„ê°€ ê²¹ì¹˜ì§€ ì•ŠìŠµë‹ˆë‹¤."}
                ),
                400,
            )

        # ì°¨íŠ¸ ë°ì´í„° ì¤€ë¹„
        chart_data = prepare_chart_data(
            portfolio_returns, benchmark_returns, portfolio_series
        )

        # í˜„ì¬ í™˜ìœ¨ ì •ë³´ (ë³´ìœ  ì¢…ëª© í…Œì´ë¸”ê³¼ ìš”ì•½ì— ì‚¬ìš©)
        exchange_rate = get_current_exchange_rate()

        # ë„ë„› ì°¨íŠ¸ ë°ì´í„° ì¤€ë¹„
        allocation_data = prepare_allocation_data(
            portfolio_data, cash_holdings, total_initial_value_with_cash
        )

        # ë³´ìœ  ì¢…ëª© í…Œì´ë¸” ë°ì´í„° ì¤€ë¹„
        holdings_table = prepare_holdings_table(
            portfolio_data, cash_holdings, base_currency, exchange_rate
        )

        # í¬íŠ¸í´ë¦¬ì˜¤ ìš”ì•½ ì •ë³´
        current_value = portfolio_series.iloc[-1]
        initial_value = portfolio_series.iloc[0]

        # í˜„ê¸ˆ ì´ì•¡ ê³„ì‚°
        total_cash = sum(cash["value"] for cash in cash_holdings.values())

        # í˜„ê¸ˆ í¬í•¨í•œ í˜„ì¬ ì´ ê°€ì¹˜
        current_value_with_cash = current_value + total_cash
        initial_value_with_cash = total_initial_value_with_cash

        summary = {
            "initial_value": round(initial_value, 2),
            "current_value": round(current_value, 2),
            "initial_value_with_cash": round(initial_value_with_cash, 2),
            "current_value_with_cash": round(current_value_with_cash, 2),
            "total_cash": round(total_cash, 2),
            "total_return": round((current_value / initial_value - 1) * 100, 2),
            "total_return_with_cash": round(
                (current_value_with_cash / initial_value_with_cash - 1) * 100, 2
            ),
            "start_date": start_date,
            "end_date": datetime.now().strftime("%Y-%m-%d"),
            "benchmark": benchmark_ticker,
            "num_holdings": len(portfolio_df),
            "base_currency": base_currency,
            "exchange_rate": round(exchange_rate, 2),
        }

        return jsonify(
            {
                "metrics": metrics,
                "chart_data": chart_data,
                "summary": summary,
                "allocation_data": allocation_data,
                "holdings_table": holdings_table,
                "warning": warning_msg,  # ê²½ê³  ë©”ì‹œì§€ ì¶”ê°€
            }
        )

    except Exception as e:
        error_trace = traceback.format_exc()
        print("=" * 80)
        print("âŒ ERROR in /analyze endpoint:")
        print(error_trace)
        print("=" * 80)
        return (
            jsonify(
                {
                    "error": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\n\nì„œë²„ í„°ë¯¸ë„ì—ì„œ ìƒì„¸ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”."
                }
            ),
            500,
        )


@app.route("/api/ai-analysis", methods=["POST"])
def ai_analysis():
    """OpenAIë¥¼ ì‚¬ìš©í•œ í¬íŠ¸í´ë¦¬ì˜¤ AI ë¶„ì„"""
    try:
        import json
        from datetime import datetime, timedelta
        
        # í´ë¼ì´ì–¸íŠ¸ IP ê°€ì ¸ì˜¤ê¸°
        client_ip = request.headers.get('X-Forwarded-For', request.remote_addr)
        if ',' in client_ip:
            client_ip = client_ip.split(',')[0].strip()
        
        current_time = datetime.now()
        
        # Rate limiting ì²´í¬ (3ë¶„ì— 1ë²ˆ)
        if client_ip in ai_analysis_rate_limit:
            last_request = ai_analysis_rate_limit[client_ip]
            time_diff = (current_time - last_request).total_seconds()
            
            if time_diff < 180:
                remaining_seconds = int(180 - time_diff)
                return jsonify({
                    "success": False,
                    "error": f"AI ë¶„ì„ì€ 3ë¶„ì— 1ë²ˆë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤. {remaining_seconds}ì´ˆ í›„ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                    "rate_limited": True,
                    "remaining_seconds": remaining_seconds
                }), 429
        
        data = request.json
        
        # í•„ìš”í•œ ë°ì´í„° ì¶”ì¶œ
        holdings = data.get("holdings", [])
        metrics = data.get("metrics", {})
        summary = data.get("summary", {})
        benchmark = summary.get("benchmark", "Unknown")
        
        # ìºì‹œ í‚¤ ìƒì„± (holdingsì˜ í‹°ì»¤ì™€ ë¹„ì¤‘ìœ¼ë¡œ)
        cache_key = json.dumps({
            "holdings": sorted([(h['ticker'], h['weight']) for h in holdings]),
            "cagr": metrics.get('cagr'),
            "sharpe": metrics.get('sharpe_ratio'),
            "benchmark": benchmark
        }, sort_keys=True)
        
        # ìºì‹œì—ì„œ í™•ì¸ (ê°™ì€ í¬íŠ¸í´ë¦¬ì˜¤ëŠ” ì¬ë¶„ì„í•˜ì§€ ì•ŠìŒ)
        if client_ip in ai_analysis_cache:
            cached_data = ai_analysis_cache[client_ip]
            if cached_data.get("cache_key") == cache_key:
                print(f"âœ… Returning cached AI analysis for IP: {client_ip}")
                return jsonify({
                    "success": True,
                    "analysis": cached_data["result"],
                    "cached": True
                })
        
        # ë²¤ì¹˜ë§ˆí¬ ì´ë¦„ ë§¤í•‘
        benchmark_names = {
            "SPY": "S&P 500",
            "^GSPC": "S&P 500",
            "QQQ": "NASDAQ 100",
            "^NDX": "NASDAQ 100",
            "069500.KS": "KOSPI 200"
        }
        benchmark_name = benchmark_names.get(benchmark, benchmark)
        
        # ë³´ìœ  ì¢…ëª© ì •ë³´ í¬ë§·íŒ…
        holdings_text = "\n".join([
            f"- {h['ticker']} ({h['name']}): {h['weight']}%"
            for h in holdings
        ])
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""ë‹¹ì‹ ì€ ì „ë¬¸ í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

## ë³´ìœ  ì¢…ëª© ë° ë¹„ì¤‘
{holdings_text}

## ì„±ê³¼ ì§€í‘œ
- ì—°í‰ê·  ìˆ˜ìµë¥  (CAGR): {metrics.get('cagr', 'N/A')}%
- ìƒ¤í”„ ë¹„ìœ¨: {metrics.get('sharpe_ratio', 'N/A')}
- ì†Œí‹°ë…¸ ë¹„ìœ¨: {metrics.get('sortino_ratio', 'N/A')}
- ì•ŒíŒŒ: {metrics.get('alpha', 'N/A')}%
- ë² íƒ€: {metrics.get('beta', 'N/A')}
- ë³€ë™ì„±: {metrics.get('volatility', 'N/A')}%
- ìµœëŒ€ ë‚™í­ (MDD): {metrics.get('max_drawdown', 'N/A')}%

## ë²¤ì¹˜ë§ˆí¬ ({benchmark_name}) ëŒ€ë¹„
- ë²¤ì¹˜ë§ˆí¬ ì—°í‰ê·  ìˆ˜ìµë¥ : {metrics.get('benchmark_annual_return', 'N/A')}%
- ë²¤ì¹˜ë§ˆí¬ ìƒ¤í”„ ë¹„ìœ¨: {metrics.get('benchmark_sharpe_ratio', 'N/A')}
- ë²¤ì¹˜ë§ˆí¬ ì†Œí‹°ë…¸ ë¹„ìœ¨: {metrics.get('benchmark_sortino_ratio', 'N/A')}
- ë²¤ì¹˜ë§ˆí¬ ë³€ë™ì„±: {metrics.get('benchmark_volatility', 'N/A')}%

ë‹¤ìŒ í•­ëª©ë“¤ì„ **ë§ˆí¬ë‹¤ìš´ í˜•ì‹**ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **í¬íŠ¸í´ë¦¬ì˜¤ ê°•ì  ë¶„ì„** (## ì œëª© ì‚¬ìš©)
   - ë²¤ì¹˜ë§ˆí¬ ëŒ€ë¹„ ìš°ìˆ˜í•œ ì 
   - ìœ„í—˜ ëŒ€ë¹„ ìˆ˜ìµë¥ ì´ ì¢‹ì€ ì´ìœ 
   - ì˜ êµ¬ì„±ëœ ë¶€ë¶„

2. **í¬íŠ¸í´ë¦¬ì˜¤ ì•½ì  ë° ìœ„í—˜ ìš”ì†Œ** (## ì œëª© ì‚¬ìš©)
   - ê°œì„ ì´ í•„ìš”í•œ ì§€í‘œ
   - ì ì¬ì  ìœ„í—˜ ìš”ì†Œ
   - ë²¤ì¹˜ë§ˆí¬ ëŒ€ë¹„ ë¶€ì¡±í•œ ì 

3. **ê°œì„  ì œì•ˆ** (## ì œëª© ì‚¬ìš©)
   - êµ¬ì²´ì ì¸ ê°œì„  ë°©ì•ˆ
   - ë¦¬ë°¸ëŸ°ì‹± ì œì•ˆ
   - ì¶”ê°€/ì œê±° ê³ ë ¤ ì¢…ëª©

ë‹µë³€ì€ ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ê³ , ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ í™œìš©í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì—¬ì£¼ì„¸ìš”.
ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

        # OpenAI API í˜¸ì¶œ
        print("ğŸ¤– Calling OpenAI API...")
        
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ ì „ë¬¸ í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ê°ê´€ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.7,
            max_tokens=2000
        )
        
        analysis_result = response.choices[0].message.content
        
        print("âœ… OpenAI API call successful")
        
        # Rate limit ì—…ë°ì´íŠ¸
        ai_analysis_rate_limit[client_ip] = current_time
        
        # ìºì‹œ ì €ì¥
        ai_analysis_cache[client_ip] = {
            "cache_key": cache_key,
            "result": analysis_result,
            "timestamp": current_time
        }
        
        return jsonify({
            "success": True,
            "analysis": analysis_result,
            "cached": False
        })
        
    except Exception as e:
        error_trace = traceback.format_exc()
        print("=" * 80)
        print("âŒ ERROR in /api/ai-analysis endpoint:")
        print(error_trace)
        print("=" * 80)
        return jsonify({
            "success": False,
            "error": f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        }), 500


if __name__ == "__main__":
    # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
    init_database()

    # Flask ì•± ì‹¤í–‰ (ì™¸ë¶€ ì ‘ì† í—ˆìš©)
    app.run(host='0.0.0.0', debug=False, port=8000)
